{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval-Augmented Generation (RAG)"
      ],
      "metadata": {
        "id": "NaB_pPaO1S2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traditional sequence-to-sequence models (T5, QWEN) generate fluent text but can “hallucinate” or rely on stale knowledge. Retrieval-Augmented Generation (RAG) mitigates these problems by drawing on an external, updatable knowledge base. When you ask a question, the system:\n",
        "\n",
        "* Retrieves the most relevant passages from its document store.\n",
        "* Augments the generation model’s input with those passages.\n",
        "* Generates an answer grounded in real text, reducing hallucinations and easing updates.\n",
        "\n"
      ],
      "metadata": {
        "id": "FITcg7uYRrQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You’ll learn how to:\n",
        "\n",
        "*   Load and preprocess the Wikitext-2 dataset via Hugging Face’s datasets library\n",
        "*   Embed and index passages using Sentence-Transformers + FAISS\n",
        "*   Wire a retriever and a lightweight Hugging Face generation model together via LangChain\n",
        "*   Run queries and dynamically add new documents to your knowledge base\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B-iOb3VqSFDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is LangChain?\n",
        "\n",
        "**LangChain** is a Python framework that simplifies building applications with large language models by providing higher-level abstractions—called chains—to stitch together components like prompt templates, LLMs, document loaders, vector stores, and external tools. It lets you:\n",
        "\n",
        "\n",
        "\n",
        "*   Load and preprocess text from files, webpages, or datasets.\n",
        "*   Split and index documents into vector databases (e.g., FAISS, Chroma, Milvus).\n",
        "*   Define chains (e.g., RetrievalQA, Summarization chains) that orchestrate retrieval, prompt construction, and generation.   \n",
        "*   Manage memory for multi-turn conversations or agents that need context.\n",
        "\n",
        "With LangChain, you can prototype complex RAG systems, chatbots, agents, and other LLM-powered workflows in just a few lines of code, without wiring each piece manually."
      ],
      "metadata": {
        "id": "-bZibamMS-5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install Dependencies"
      ],
      "metadata": {
        "id": "STtSfY42ST9y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTZzpYDDO36k",
        "outputId": "e5f232b4-f471-4cd6-971d-839b72504533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (2025.3.0)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2025.5.1\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.5.1\n",
            "    Uninstalling fsspec-2025.5.1:\n",
            "      Successfully uninstalled fsspec-2025.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2025.3.0\n"
          ]
        }
      ],
      "source": [
        "# Force-upgrade fsspec\n",
        "!pip install --upgrade fsspec\n",
        "\n",
        "# Core RAG stack\n",
        "!pip install --upgrade \\\n",
        "  langchain \\\n",
        "  datasets \\\n",
        "  langchain-community \\\n",
        "  transformers \\\n",
        "  sentence-transformers \\\n",
        "  faiss-cpu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 2. Loading the Dataset\n",
        "We’ll use the Wikitext-2 “raw” split, which provides plain-text Wikipedia articles:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XIOpKfGcShvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "streamed = load_dataset(\"isaacus/open-australian-legal-corpus\", split=\"corpus\", streaming=True)\n",
        "\n",
        "docs = []\n",
        "total_chars = 0\n",
        "for row in streamed:\n",
        "    text = row[\"text\"].strip()\n",
        "    if not text:\n",
        "        continue\n",
        "    docs.append(text)\n",
        "    total_chars += len(text)\n",
        "    if total_chars >= 150_000_000:  # ≈ 150 MB\n",
        "        break\n",
        "\n",
        "print(f\"Loaded {len(docs)} streamed passages (~1 GB)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CazDM7KpSkAz",
        "outputId": "23216680-9b4f-4142-d850-81ab101b9f21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 3362 streamed passages (~1 GB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preprocessing & Chunking\n",
        "Long articles need splitting into manageable “chunks” (e.g. 200-token windows) for embedding:\n",
        "\n"
      ],
      "metadata": {
        "id": "q8_IR_XISuzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def chunk_text(text, chunk_size=200, overlap=50):\n",
        "    tokens = text.split()\n",
        "    for i in range(0, len(tokens), chunk_size - overlap):\n",
        "        yield \" \".join(tokens[i : i + chunk_size])\n",
        "\n",
        "# Build a list of chunks\n",
        "chunks = list(itertools.chain.from_iterable(chunk_text(doc) for doc in docs))\n",
        "print(f\"Created {len(chunks)} text chunks\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWNxKwkmSgGv",
        "outputId": "9c8da372-6508-463f-dd7b-841d4509749c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 157824 text chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Embedding the Documents\n",
        "We’ll use a Sentence-Transformers model via LangChain’s HuggingFaceEmbeddings:\n"
      ],
      "metadata": {
        "id": "zxULITXBXDLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Choose a compact, high-quality embedding model\n",
        "embed_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=embed_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkHvOOLUS3js",
        "outputId": "694edf29-35cf-4727-eb4d-c2793054a992"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-1864289813>:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=embed_model)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Building the Vector Store\n",
        "Index the embedded chunks with FAISS:\n"
      ],
      "metadata": {
        "id": "ILTDFNInqSdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Create (or load) a FAISS index\n",
        "vectorstore = FAISS.from_texts(chunks, embeddings)\n"
      ],
      "metadata": {
        "id": "d9kH6uffXF6U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Creating the RAG Pipeline\n",
        "We’ll pair a lightweight Hugging Face generation model (Flan-T5) with our retriever:\n"
      ],
      "metadata": {
        "id": "6c23O1U5qX08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# 1. Load a text2text-generation pipeline\n",
        "gen_model_id = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(gen_model_id)\n",
        "model     = AutoModelForSeq2SeqLM.from_pretrained(gen_model_id)\n",
        "hf_pipeline = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=256,\n",
        ")\n",
        "\n",
        "# 2. Wrap it for LangChain\n",
        "llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "\n",
        "# 3. Build the RetrievalQA chain\n",
        "rag = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",          # “stuff” for simple prompt-plus-context\n",
        "    retriever=vectorstore.as_retriever(),\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJRLchfRp6_g",
        "outputId": "29407631-cc36-479a-be64-44651f4bcb5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "<ipython-input-6-3979335182>:17: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=hf_pipeline)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Querying Your RAG System\n",
        "Now ask a question:\n"
      ],
      "metadata": {
        "id": "HW49HcKVqdPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"When was the Melbourne Courts were formed?\"\n",
        "answer = rag.run(question)\n",
        "print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr0cOPggp764",
        "outputId": "1917dc59-2f5b-49fe-fc3f-2d40df327707"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-284772910>:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  answer = rag.run(question)\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: The trial of the action took place in Melbourne, delivered judgment in Sydney on the footing that the law of Victoria applied \"to avoid keeping the parties waiting until the Court next sits in Melbourne\" and \"on the view, which both parties urge, that jurisdiction in the case is to be taken as having been exercised in Victoria\" [48]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Dynamically Updating the Knowledge Base\n",
        "You can update your knowledge base on the fly and immediately see the effect in your RAG answers. Below is an example that:\n",
        "\n",
        "* Queries the system before adding a new document (and gets no or stale answer).\n",
        "* Adds a new document containing a specific fact.\n",
        "* Rebuilds the RAG chain (to pick up the new text).\n",
        "* Queries after adding the document, yielding the correct, updated answer."
      ],
      "metadata": {
        "id": "6CT90ZQ-qkwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before adding documents\n"
      ],
      "metadata": {
        "id": "RioedxNO0EgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"when australia passed aborginal act?\"\n",
        "answer = rag.run(question)\n",
        "print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDCMBUTQz67u",
        "outputId": "6ec51f06-9c00-49bf-bfea-2b8b4236ead4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Act 1999 of the Commonwealth. which this Act commenced. action Where any provision of an Act, regulation, rule or by-law requires a person to give notice of his intention to bring an action, or of any claim that he intends to prosecute in an action, before the action is instituted in a court, the court may, if the justice of the case so requires, at any time before or after the close of pleadings, dispense with that requirement. Legislative history Notes • Please note—References in the legislation to other legislation or instruments or to titles of bodies or offices are not automatically updated as part of the program for the revision and publication of legislation and therefore may be obsolete. • Earlier versions of this Act (historical versions) are listed at the end of the legislative history. • For further information relating to the Act and subordinate legislation made under the Act see the Index of South Australian Statutes or www.legislation.sa.gov.au. Principal Act Year|No|Title|Assent|Commencement|2012|30|National Health Funding Pool Administration (South Australia) Act 2012 |13.9.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add a new document"
      ],
      "metadata": {
        "id": "TT7UOQhJ0GHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_docs = [\n",
        "    \"The Aboriginal Land Rights (Northern Territory) Act was passed in December 1976. This legislation was a landmark piece of social reform, allowing First Nations people to claim land title if they could prove a traditional association. \",\n",
        "]\n",
        "vectorstore.add_texts(new_docs)\n",
        "\n",
        "# Build the RetrievalQA chain\n",
        "rag = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",          # “stuff” for simple prompt-plus-context\n",
        "    retriever=vectorstore.as_retriever(),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "sgWqGs4sp9OT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After adding new document\n",
        "\n"
      ],
      "metadata": {
        "id": "9uKY2zXH0JT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"when australia passed aborginal act?\"\n",
        "answer = rag.run(question)\n",
        "print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7byGlsxtqZD",
        "outputId": "a028fae0-73f8-4113-e6a2-9999be7e2981"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Act 1999 of the Commonwealth. which this Act commenced. action Where any provision of an Act, regulation, rule or by-law requires a person to give notice of his intention to bring an action, or of any claim that he intends to prosecute in an action, before the action is instituted in a court, the court may, if the justice of the case so requires, at any time before or after the close of pleadings, dispense with that requirement. Legislative history Notes • Please note—References in the legislation to other legislation or instruments or to titles of bodies or offices are not automatically updated as part of the program for the revision and publication of legislation and therefore may be obsolete. • Earlier versions of this Act (historical versions) are listed at the end of the legislative history. • For further information relating to the Act and subordinate legislation made under the Act see the Index of South Australian Statutes or www.legislation.sa.gov.au. Principal Act Year|No|Title|Assent|Commencement|2012|30|National Health Funding Pool Administration (South Australia) Act 2012 |13.9.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag.run(\"When was the Aboriginal Land Rights Act passed?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hPgBckAVoVLl",
        "outputId": "019dd69c-751d-42b7-abb9-232a0b03e55e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'December 1976'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()\n",
        "docs = retriever.get_relevant_documents(\"when australia passed aboriginal act?\")\n",
        "for d in docs:\n",
        "    print(d.page_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6FQcn43obxY",
        "outputId": "5373fd5f-1d13-4fad-f481-d92d209a1757"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Volume 7 of The Public General Acts of South Australia 1837-1975 at page 540. • Certain textual alterations were made to this Act by the Commissioner of Statute Revision when preparing the reprint of the Act that incorporated all amendments in force as at 11 July 1988. A schedule of these alterations was laid before Parliament on 16 August 1988. New entries appear in bold. Entries that relate to provisions that have been deleted appear in italics. Provision|How varied|Commencement| Pt 1||| ss 2 and 3|deleted in pursuance of the Acts Republication Act 1967 as their function is now exhausted|11.7.1988| s 4|amended by 35/1978 s 3|8.6.1978| |amended by 100/1978 s 3|14.8.1980| |deleted by 94/1987 Sch|17.12.1987| s 5||| Aboriginal|inserted by 27/2004 s 13(1)|29.7.2004| Aboriginal-owned land|inserted by 27/2004 s 13(1)|29.7.2004| Aboriginal person|inserted by 27/2004 s 13(1)|29.7.2004| Adelaide Dolphin Sanctuary|inserted by 5/2005 Sch 2 (cl 42)|4.6.2005| aircraft|inserted by 94/1987 s 3(a)|17.12.1987| appointed member|inserted by 13/1996 s 3(a)|23.5.1996| the Advisory Council|deleted by 100/1978 s 4(b)|14.8.1980| appointed member|deleted by 100/1978 s 4(a)|14.8.1980| carcass|substituted by 94/1987 s 3(b)|17.12.1987| the Chief Executive Officer|inserted by 94/1987 s 3(j)|17.12.1987| |amended by 62/2000 Sch|24.8.2000| co-managed park|inserted by 27/2004 s 13(2)|29.7.2004| co-management advisory committee|inserted by 2/2017 s 3|28.2.2017| co-management agreement|inserted by 27/2004\n",
            "Matter No . 40123 of 1999 ENVIRONMENT COURT OF Coram : Bignold J. NEW SOUTH WALES 30 July 1999 R J LESTER, W MURRAY, M RITCHIE, R TOWNEY Applicants v NEW SOUTH WALES ABORIGINAL LAND COUNCIL First Respondent OSWALD CRUSE As Chairperson of the New South Wales Aboriginal Land Council Second Respondent JUDGMENT ON PRELIMINARY QUESTION Bignold J: A. INTRODUCTION 1. On 29 June 1999, the Applicant's commenced class 4 proceedings claiming the following relief: 1. A declaration that the office of the Applicants Lester, Murray, Ritchie and Towney as Councillors of the First Respondent has not become vacant under clause 3(i) of Schedule 5 of the Aboriginal Land Rights Act 1983 (the Act) by reason of the following events: (a) the election of the said Applicants to the office of member of the Regional Council established under the Aboriginal and Torres Strait Island Commission Act 1989 (Commonwealth (the ATSIC Act); (b) the holding of that office by each of the said applicants; or (c) payment of such remuneration and allowances as the said applicants are entitled to received under s 118 of the ATSIC Act by reason of that office or the performance of the duties of that office.\n",
            "The Aboriginal Land Rights (Northern Territory) Act was passed in December 1976. This legislation was a landmark piece of social reform, allowing First Nations people to claim land title if they could prove a traditional association. \n",
            "South Australia Aboriginal Representative Body Bill 2022 A Bill For An Act to give Aboriginal people a voice that will be heard by the Parliament of South Australia, the Cabinet, State authorities and other persons and bodies, to establish the Commissioner for Aboriginal Engagement, to establish the Aboriginal Representative Body, to repeal the Aboriginal Lands Parliamentary Standing Committee Act 2003, to make a related amendment to the Parliamentary Committees Act 1991, and for other purposes. Contents Preamble Part 1—Preliminary 1 Short title 2 Commencement 3 Interpretation 4 Aboriginal persons 5 Aboriginal elders 6 Interaction with other Acts and laws Part 2—Purposes and principles of Act 7 Purposes of Act 8 Principles to be observed in operation of Act 9 Aboriginal Representative Body to represent views of all Aboriginal persons in South Australia 10 Aboriginal Representative Body and committees to work together to ensure Aboriginal voice is heard Part 3—Commissioner for Aboriginal Engagement 11 Commissioner for Aboriginal Engagement 12 Appointment of Commissioner 13 Functions of Commissioner 14 Appointment of acting Commissioner 15 Interaction with Public Sector (Honesty and Accountability) Act 16 Delegation 17 Staff and resources 18 Annual report Part 4—Aboriginal Representative Body Division 1—Aboriginal Representative Body 19 Establishment of Aboriginal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-1721236737>:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(\"when australia passed aboriginal act?\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before adding documents"
      ],
      "metadata": {
        "id": "kX7_00Er0A9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"when australia abortion law passed?\"\n",
        "answer = rag.run(question)\n",
        "print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWVQZBEXz8ae",
        "outputId": "d16b6dda-bf1d-47f9-b9cb-64d2f16021ae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: No, it's not possible to tell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add a new document"
      ],
      "metadata": {
        "id": "nouLYCte0MLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_docs = [\n",
        "    \"In Victoria, abortion was decriminalized by the Abortion Law Reform Act 2008. This act also established guidelines for when abortions could take place. Abortion laws vary by state and territory in Australia, with some states requiring medical assessments and others allowing for broader access.\",\n",
        "]\n",
        "vectorstore.add_texts(new_docs)\n",
        "\n",
        "# Build the RetrievalQA chain\n",
        "rag = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",          # “stuff” for simple prompt-plus-context\n",
        "    retriever=vectorstore.as_retriever(),\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "-mUKb-CYuUI8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After adding new document"
      ],
      "metadata": {
        "id": "WIls9lLw0PCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"when australia abortion law passed?\"\n",
        "answer = rag.run(question)\n",
        "print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhVfqs6_t6oj",
        "outputId": "01749fbe-541c-401e-c7e1-7c781dcad9bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: In Victoria, abortion was decriminalized by the Abortion Law Reform Act 2008. This act also established guidelines for when abortions could take place. Abortion laws vary by state and territory in Australia, with some states requiring medical assessments and others allowing for broader access. abortion does not constitute an offence under a written law. (2) Subsection (1) applies whether the death occurs before, on or after the day on which the Abortion Legislation Reform Act 2023 section 20 comes into operation. [Section 3B inserted: No. 27 of 2020 s. 54.] Part 2 — Coroners and Coroner's court Division 1 — Coroner's court 5. Establishment of court (1) A court to be known as the Coroner's Court of Western Australia is established. (2) The court is to be constituted by a coroner and has exclusive jurisdiction to hold all inquests under this Act. (3) The court constituted by a coroner may sit and exercise the jurisdiction of a person who has selfadministered, or has been administered, a voluntary assisted dying substance in accordance with the Voluntary \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UR4BgIoSuzzH"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}